{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Death events by heart attack: prediction model\n",
    "### The data is imbalanced and I have not treated that and the dataset contained also has its outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>204000.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  65.0        0                       146         0                 20   \n",
       "2  50.0        1                       111         0                 20   \n",
       "3  90.0        1                        47         0                 40   \n",
       "4  75.0        1                       246         0                 15   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1   265000.0               1.9           130    1   \n",
       "1                    0   162000.0               1.3           129    1   \n",
       "2                    0   210000.0               1.9           137    1   \n",
       "3                    1   204000.0               2.1           132    1   \n",
       "4                    0   127000.0               1.2           137    1   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        1     7            1  \n",
       "2        0     7            1  \n",
       "3        1     8            1  \n",
       "4        0    10            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"removed_outliers_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEATH_EVENT\n",
      "0    163\n",
      "1     61\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count check of classes in dependent variable\n",
    "death_event_counts=df['DEATH_EVENT'].value_counts()\n",
    "print(death_event_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting  important features\n",
    "filtered_df = df[['age', 'ejection_fraction', 'serum_creatinine','DEATH_EVENT']]\n",
    "X=filtered_df.iloc[:,0:3]\n",
    "y=filtered_df.iloc[:,3]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test=sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEATH_EVENT\n",
      "0    33\n",
      "1    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Count of y variable's test set \n",
    "death_event_counts2 = y_test.value_counts()\n",
    "print(death_event_counts2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 68.89%\n",
      "Accuracy for Training Data: 82.68%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       130\n",
      "           1       0.75      0.55      0.64        49\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.80      0.74      0.76       179\n",
      "weighted avg       0.82      0.83      0.82       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        33\n",
      "           1       0.40      0.33      0.36        12\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.59      0.58      0.58        45\n",
      "weighted avg       0.67      0.69      0.68        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression()\n",
    "lr1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_lr1=lr1.predict(X_train)\n",
    "ytest_pred_lr1=lr1.predict(X_test)\n",
    "\n",
    "classifiers = [lr1, lr1]\n",
    "predictions = [ytest_pred_lr1, ytrain_pred_lr1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "train_report1 = classification_report(y_train, ytrain_pred_lr1)\n",
    "test_report1 = classification_report(y_test, ytest_pred_lr1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report1)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best Accuracy: 0.8100000000000002\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametric tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Different values of the regularization parameter\n",
    "    'penalty': ['l1', 'l2']  # Types of regularization (L1 or L2)\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=lr1, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Training Data (Best LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89       130\n",
      "           1       0.88      0.45      0.59        49\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.85      0.71      0.74       179\n",
      "weighted avg       0.84      0.83      0.81       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data (Best LR):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81        33\n",
      "           1       0.33      0.17      0.22        12\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.54      0.52      0.51        45\n",
      "weighted avg       0.63      0.69      0.65        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a LogisticRegression instance with the best hyperparameters\n",
    "best_lr = LogisticRegression(C=best_params['C'], penalty=best_params['penalty'])\n",
    "\n",
    "# Fit the best logistic regression model to the training data\n",
    "best_lr.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the best_lr model for predictions and evaluation\n",
    "ytrain_pred_best_lr = best_lr.predict(X_train)\n",
    "ytest_pred_best_lr = best_lr.predict(X_test)\n",
    "\n",
    "# Calculate the classification report for the best_lr model\n",
    "train_report_best_lr = classification_report(y_train, ytrain_pred_best_lr)\n",
    "test_report_best_lr = classification_report(y_test, ytest_pred_best_lr)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data (Best LR):\\n\", train_report_best_lr)\n",
    "print(\"\\nClassification Report for Testing Data (Best LR):\\n\", test_report_best_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the dataset is not balanced, i.e., its 0s are more in number than 1s, hence hyperparametric tuning is not going to do much good. As you can see above, after hpt, the precision and recall scores worsened as seen before hpt. Hence, I have not performed one for either models below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 73.33%\n",
      "Accuracy for Training Data: 84.92%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       130\n",
      "           1       0.76      0.65      0.70        49\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.82      0.79      0.80       179\n",
      "weighted avg       0.84      0.85      0.85       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        33\n",
      "           1       0.50      0.42      0.45        12\n",
      "\n",
      "    accuracy                           0.73        45\n",
      "   macro avg       0.65      0.63      0.64        45\n",
      "weighted avg       0.72      0.73      0.73        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm1=SVC(kernel='rbf',random_state=0)\n",
    "svm1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_svm1=svm1.predict(X_train)\n",
    "ytest_pred_svm1=svm1.predict(X_test)\n",
    "\n",
    "classifiers = [svm1, svm1]\n",
    "predictions = [ytest_pred_svm1, ytrain_pred_svm1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "train_report2 = classification_report(y_train, ytrain_pred_svm1)\n",
    "test_report2 = classification_report(y_test, ytest_pred_svm1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report2)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 66.67%\n",
      "Accuracy for Training Data: 83.80%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       130\n",
      "           1       0.78      0.57      0.66        49\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.82      0.75      0.78       179\n",
      "weighted avg       0.83      0.84      0.83       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        33\n",
      "           1       0.38      0.42      0.40        12\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.58      0.59      0.58        45\n",
      "weighted avg       0.68      0.67      0.67        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn1=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "knn1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_knn1=knn1.predict(X_train)\n",
    "ytest_pred_knn1=knn1.predict(X_test)\n",
    "\n",
    "classifiers = [knn1, knn1]\n",
    "predictions = [ytest_pred_knn1, ytrain_pred_knn1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "train_report3 = classification_report(y_train, ytrain_pred_knn1)\n",
    "test_report3 = classification_report(y_test, ytest_pred_knn1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report3)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Niave bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 68.89%\n",
      "Accuracy for Training Data: 76.54%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       130\n",
      "           1       0.62      0.37      0.46        49\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.71      0.64      0.66       179\n",
      "weighted avg       0.75      0.77      0.74       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81        33\n",
      "           1       0.25      0.08      0.12        12\n",
      "\n",
      "    accuracy                           0.69        45\n",
      "   macro avg       0.49      0.50      0.47        45\n",
      "weighted avg       0.60      0.69      0.63        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb1=BernoulliNB()\n",
    "nb1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_nb1=nb1.predict(X_train)\n",
    "ytest_pred_nb1=nb1.predict(X_test)\n",
    "\n",
    "classifiers = [nb1, nb1]\n",
    "predictions = [ytest_pred_nb1, ytrain_pred_nb1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "train_report4 = classification_report(y_train, ytrain_pred_nb1)\n",
    "test_report4 = classification_report(y_test, ytest_pred_nb1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report4)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 71.11%\n",
      "Accuracy for Training Data: 98.88%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       130\n",
      "           1       1.00      0.96      0.98        49\n",
      "\n",
      "    accuracy                           0.99       179\n",
      "   macro avg       0.99      0.98      0.99       179\n",
      "weighted avg       0.99      0.99      0.99       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        33\n",
      "           1       0.47      0.58      0.52        12\n",
      "\n",
      "    accuracy                           0.71        45\n",
      "   macro avg       0.65      0.67      0.66        45\n",
      "weighted avg       0.74      0.71      0.72        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt1=DecisionTreeClassifier()\n",
    "dt1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_dt1=dt1.predict(X_train)\n",
    "ytest_pred_dt1=dt1.predict(X_test)\n",
    "\n",
    "classifiers = [dt1, dt1]\n",
    "predictions = [ytest_pred_dt1, ytrain_pred_dt1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "train_report5_a = classification_report(y_train, ytrain_pred_dt1)\n",
    "test_report5_a = classification_report(y_test, ytest_pred_dt1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report5_a)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report5_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Testing Data: 71.11%\n",
      "Accuracy for Training Data: 98.88%\n",
      "Classification Report for Training Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       130\n",
      "           1       1.00      0.96      0.98        49\n",
      "\n",
      "    accuracy                           0.99       179\n",
      "   macro avg       0.99      0.98      0.99       179\n",
      "weighted avg       0.99      0.99      0.99       179\n",
      "\n",
      "\n",
      "Classification Report for Testing Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.81        33\n",
      "           1       0.45      0.42      0.43        12\n",
      "\n",
      "    accuracy                           0.71        45\n",
      "   macro avg       0.62      0.62      0.62        45\n",
      "weighted avg       0.70      0.71      0.71        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf1=RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "rf1.fit(X_train,y_train)\n",
    "\n",
    "ytrain_pred_rf1=rf1.predict(X_train)\n",
    "ytest_pred_rf1=rf1.predict(X_test)\n",
    "\n",
    "classifiers = [rf1, rf1]\n",
    "predictions = [ytest_pred_rf1, ytrain_pred_rf1]\n",
    "data_names = [\"Testing Data\", \"Training Data\"]\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    accuracy = accuracy_score(y_test, predictions[i]) if i == 0 else accuracy_score(y_train, predictions[i])\n",
    "    data_name = data_names[i]\n",
    "    print(f\"Accuracy for {data_name}: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "train_report6_a = classification_report(y_train, ytrain_pred_rf1)\n",
    "test_report6_a = classification_report(y_test, ytest_pred_rf1)\n",
    "\n",
    "# Print the classification reports\n",
    "print(\"Classification Report for Training Data:\\n\", train_report6_a)\n",
    "print(\"\\nClassification Report for Testing Data:\\n\", test_report6_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have observed that decision tree classifier is giving the best results of precision and recall scores as compared to others, hence we are going to go ahead with that model finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
